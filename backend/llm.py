"""
LangChain ç‰ˆç§Ÿæˆ¿åˆåŒåŠ©æ‰‹
- æ”¯æŒ TenantChatbot ç±»
- æ”¯æŒ RAG é—®ç­”ã€æ„å›¾åˆ†ç±»ã€æ™®é€šå¯¹è¯
- ä¿ç•™ä½ ä¹‹å‰çš„å¯¼å…¥æ–¹å¼ï¼Œå…¼å®¹ Python 3.11
"""

from dotenv import load_dotenv
load_dotenv()

import os
import json

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ==============================
# é…ç½®
# ==============================
PDF_PATH = "backend/Track_B_Tenancy_Agreement.pdf"
VECTOR_DIR = "backend/vector_store"

# ==============================
# RAG é—®ç­”æ¨¡æ¿
# ==============================
QA_TEMPLATE = """You are a tenancy contract assistant.
Use ONLY the contract excerpts below to answer the user's question.

--- CONTRACT CONTEXT START ---
{context}
--- CONTRACT CONTEXT END ---

Question: {question}

Guidelines:
- Cite clause numbers if available.
- If unclear, say 'Not sure, please check with landlord.'
- Provide answer in JSON:
{{ "answer": "...", "citations": [], "confidence": "high|medium|low" }}
"""

# ==============================
# PDF å‘é‡åŒ– & å‘é‡åº“
# ==============================
def ensure_vector_store(pdf_path: str = PDF_PATH, persist_dir: str = VECTOR_DIR):
    """
    å¦‚æœ Chroma å‘é‡åº“ä¸å­˜åœ¨ï¼Œåˆ™åŠ è½½ PDF å¹¶åˆ›å»ºã€‚
    """
    if os.path.exists(persist_dir) and os.listdir(persist_dir):
        print("âœ… å·²æ£€æµ‹åˆ°ç°æœ‰å‘é‡åº“ï¼Œè·³è¿‡é‡å»ºã€‚")
        return Chroma(persist_directory=persist_dir, embedding_function=OpenAIEmbeddings())

    if not os.path.exists(pdf_path):
        print(f"âš ï¸ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return None

    print("ğŸ“„ æ­£åœ¨åŠ è½½åˆåŒ PDF å¹¶ç”Ÿæˆå‘é‡...")
    loader = PyPDFLoader(pdf_path)
    docs = loader.load()

    # åˆ‡åˆ†æ–‡æœ¬
    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150)
    chunks = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    vectordb = Chroma.from_documents(chunks, embedding=embeddings, persist_directory=persist_dir)
    vectordb.persist()

    print(f"âœ… PDF å‘é‡åŒ–å®Œæˆï¼š{len(chunks)} ä¸ªç‰‡æ®µå·²å…¥åº“ã€‚")
    return vectordb

# ==============================
# æ„å›¾è¯†åˆ«
# ==============================
def classify_intent(user_input: str) -> str:
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    prompt = PromptTemplate(
        input_variables=["message"],
        template=(
            "Classify this user message into one of: "
            "contract_qa, repair_request, status_check.\n\n"
            "Message: {message}\nReturn only the label."
        ),
    )
    from langchain.chains import LLMChain
    chain = LLMChain(prompt=prompt, llm=llm)
    result = chain.invoke({"message": user_input})
    label = result["text"].strip().lower()
    if label not in {"contract_qa", "repair_request", "status_check"}:
        label = "contract_qa"
    return label

# ==============================
# TenantChatbot ç±»
# ==============================
class TenantChatbot:
    def __init__(self, vectordb, llm, memory=None):
        self.vectordb = vectordb
        self.llm = llm
        self.memory = memory
        # åˆå§‹åŒ– RAG QA
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.vectordb.as_retriever(search_kwargs={"k": 5}),
            chain_type="stuff",
            chain_type_kwargs={
                "prompt": PromptTemplate(
                    input_variables=["context", "question"],
                    template=QA_TEMPLATE
                )
            }
        )

    def process_query(self, query: str):
        # å…ˆåˆ†ç±»æ„å›¾
        intent = classify_intent(query)
        if intent == "contract_qa":
            return self.qa_chain.run(query)
        elif intent == "repair_request":
            return "ğŸ› ï¸ Repair request noted. Please provide location, issue type, urgency, and photo link."
        elif intent == "status_check":
            return "ğŸ” Please provide your ticket number (e.g., T2025-001)."
        else:
            return "â“ Iâ€™m not sure I understood. Could you rephrase."

# ==============================
# æµ‹è¯•ç¤ºä¾‹
# ==============================
if __name__ == "__main__":
    vectordb = ensure_vector_store()
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
    chatbot = TenantChatbot(vectordb=vectordb, llm=llm)

    test_queries = [
        # åˆåŒæ¡æ¬¾ç±»ï¼ˆRAGï¼‰
        "Who is responsible for aircon maintenance?",
        "Can I terminate the lease early?",
        "What does the clause say about deposit refund?",
        # è®¡ç®—ç±»ï¼ˆAgentï¼‰
        "Calculate total rent if monthly rent is $2500 for 15 months.",
        # ä¸€èˆ¬å¯¹è¯ï¼ˆMemoryï¼‰
        "I'm confused about my lease renewal. What should I check first?"
    ]

    for q in test_queries:
        print('\n' + '='*70)
        print('Q:', q)
        try:
            ans = chatbot.process_query(q)
            print('A:', ans)
        except Exception as e:
            print('â—Error running query:', e)
